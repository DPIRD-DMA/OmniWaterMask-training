{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Tiling and Mask Preparation\n",
    "\n",
    "In this notebook, the **S1S2 dataset** is split into **512 × 512 pixel tiles** with a small amount of overlap.\n",
    "\n",
    "Some images contain **NoData regions**. These regions are indicated in the corresponding *validity masks*, where:\n",
    "\n",
    "- `0` → Invalid (NoData)  \n",
    "- `1` → Valid  \n",
    "\n",
    "To ensure these areas are ignored during training:\n",
    "\n",
    "- All invalid (`0`) pixels from the validity mask are **burned into the segmentation mask** using the value `99`.\n",
    "- The value `99` is configured as an **ignore label** during model training.\n",
    "\n",
    "This approach prevents NoData regions from influencing the loss or evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import rasterio as rio\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing.pool import ThreadPool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 512\n",
    "water_value = 1\n",
    "background_value = 0\n",
    "stride = 412\n",
    "do_L2A = True\n",
    "image_bands = [1, 2, 3, 4]\n",
    "expected_image_channels = len(image_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"/media/nick/4TB Working 6/Datasets/S1S2-Water/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_patches_dir = data_dir / \"images\"\n",
    "mask_patches_dir = data_dir / \"labels\"\n",
    "\n",
    "img_patches_dir.mkdir(exist_ok=True, parents=True)\n",
    "mask_patches_dir.mkdir(exist_ok=True)\n",
    "img_patches_dir, mask_patches_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1s2_folders = data_dir.parent\n",
    "s1s2_folders.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_folders = list(\n",
    "    set(s1s2_folders.glob(\"part*\")) - set(s1s2_folders.glob(\"part*.zip\"))\n",
    ")\n",
    "part_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_imgs = []\n",
    "s2_img_L2A = []\n",
    "for folder in part_folders:\n",
    "    s2_imgs.extend(list(folder.rglob(\"*sentinel12_s2_*_img.tif\")))\n",
    "    s2_img_L2A.extend(list(folder.rglob(\"*sentinel12_s2_*_L2A*.tif\")))\n",
    "\n",
    "if not do_L2A:\n",
    "    s2_imgs = [x for x in s2_imgs if x not in s2_img_L2A]\n",
    "len(s2_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_imgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patch(\n",
    "    input_array: np.ndarray,\n",
    "    top: int,\n",
    "    bottom: int,\n",
    "    left: int,\n",
    "    right: int,\n",
    "    input_raster_path: Path,\n",
    "    dataset: str,\n",
    "    src: rio.DatasetReader,\n",
    "    patch_dir: Path,\n",
    "    label: bool = False,\n",
    "    background_value: int = 0,\n",
    "    water_value: int = 1,\n",
    ") -> None:\n",
    "    patch = input_array[:, top:bottom, left:right]\n",
    "    file_name = input_raster_path.stem\n",
    "    file_name = file_name.replace(\"_msk\", \"\")\n",
    "    file_name = file_name.replace(\"_img\", \"\")\n",
    "    # file_name = file_name.replace(replace_for_mask, \"\")\n",
    "    patch_path = patch_dir / f\"{file_name}_{dataset}_{top}_{bottom}_{left}_{right}.tif\"\n",
    "\n",
    "    local_profile = src.profile.copy()\n",
    "    local_profile.update(\n",
    "        {\"height\": patch_size, \"width\": patch_size, \"count\": patch.shape[0]}\n",
    "    )\n",
    "    local_profile.update(\n",
    "        {\"transform\": src.window_transform(window=((top, bottom), (left, right)))}\n",
    "    )\n",
    "    if label:\n",
    "        patch[patch == 0] = background_value\n",
    "        patch[patch == 1] = water_value\n",
    "    if patch.shape[-2] != patch_size or patch.shape[-1] != patch_size:\n",
    "        print(patch.shape)\n",
    "        raise ValueError(\"Patch shape is not 512x512\")\n",
    "\n",
    "    with rio.open(patch_path, \"w\", **local_profile) as dst:\n",
    "        dst.write(patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for img in tqdm(s2_imgs):\n",
    "def make_patches(img: Path) -> None:\n",
    "    metadata = list(img.parent.glob(\"*meta.json\"))[0]\n",
    "\n",
    "    meta = json.load(metadata.open())\n",
    "    dataset = meta[\"properties\"][\"split\"]\n",
    "\n",
    "    src = rio.open(img)\n",
    "    img_array = src.read(image_bands)\n",
    "\n",
    "    is_l2a = \"L2A\" in img.name\n",
    "\n",
    "    label_path = img.parent / img.name.replace(\"img\", \"msk\").replace(\"_L2A\", \"\")\n",
    "\n",
    "    valid_path = img.parent / img.name.replace(\"img\", \"valid\").replace(\"_L2A\", \"\")\n",
    "\n",
    "    label_src = rio.open(label_path)\n",
    "    label_array = label_src.read()\n",
    "    valid_array = rio.open(valid_path).read()\n",
    "    # where array is 0 set label to 99\n",
    "    label_array[valid_array == 0] = 99\n",
    "\n",
    "    assert img_array.shape[0] == expected_image_channels, (\n",
    "        f\"Expected {expected_image_channels} channels, got {img_array.shape[0]}\"\n",
    "    )\n",
    "\n",
    "    top = 0\n",
    "    while True:\n",
    "        bottom = top + patch_size\n",
    "        left = 0\n",
    "        while True:\n",
    "            right = left + patch_size\n",
    "\n",
    "            extract_patch(\n",
    "                input_array=img_array,\n",
    "                top=top,\n",
    "                bottom=bottom,\n",
    "                left=left,\n",
    "                right=right,\n",
    "                input_raster_path=img,\n",
    "                src=src,\n",
    "                dataset=dataset,\n",
    "                patch_dir=img_patches_dir,\n",
    "                label=False,\n",
    "            )\n",
    "            if not is_l2a:  # avoid making duplicate labels for l2a images\n",
    "                extract_patch(\n",
    "                    input_array=label_array,\n",
    "                    top=top,\n",
    "                    bottom=bottom,\n",
    "                    left=left,\n",
    "                    right=right,\n",
    "                    input_raster_path=label_path,\n",
    "                    src=label_src,\n",
    "                    dataset=dataset,\n",
    "                    patch_dir=mask_patches_dir,\n",
    "                    label=True,\n",
    "                    background_value=background_value,\n",
    "                    water_value=water_value,\n",
    "                )\n",
    "\n",
    "            left += stride\n",
    "            right = left + patch_size\n",
    "\n",
    "            if right >= label_array.shape[2]:\n",
    "                break\n",
    "\n",
    "        top += stride\n",
    "        bottom = top + patch_size\n",
    "\n",
    "        if bottom >= label_array.shape[1]:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ThreadPool(16) as p:\n",
    "    results = list(tqdm(p.imap(make_patches, s2_imgs), total=len(s2_imgs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_imgs(patch_path):\n",
    "    try:\n",
    "        array = rio.open(patch_path).read()\n",
    "    except Exception as e:\n",
    "        print(f\"{patch_path} failed check {e}\")\n",
    "        return\n",
    "    try:\n",
    "        assert array.shape[-2] == patch_size\n",
    "        assert array.shape[-1] == patch_size\n",
    "        # assert array.shape[0] == 6\n",
    "    except AssertionError:\n",
    "        print(f\"{patch_path} failed check, {array.shape}\")\n",
    "    try:\n",
    "        file_name = patch_path.name\n",
    "        label_file_name = file_name.replace(\"_L2A\", \"\")\n",
    "        label_path = mask_patches_dir / label_file_name\n",
    "        assert label_path.exists()\n",
    "    except AssertionError:\n",
    "        print(f\"{label_path} does not exist\")\n",
    "\n",
    "\n",
    "def check_masks(patch_path):\n",
    "    try:\n",
    "        array = rio.open(patch_path).read()\n",
    "    except Exception as e:\n",
    "        print(f\"{patch_path} failed check {e}\")\n",
    "        return\n",
    "    try:\n",
    "        assert array.shape[-2] == patch_size\n",
    "        assert array.shape[-1] == patch_size\n",
    "        assert array.shape[0] == 1\n",
    "    except AssertionError:\n",
    "        print(f\"{patch_path} failed check, {array.shape}\")\n",
    "    try:\n",
    "        assert np.all(np.isin(array, [0, 1, 99]))\n",
    "    except AssertionError:\n",
    "        print(f\"{patch_path} failed check, {np.unique(array)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_patches = list(img_patches_dir.rglob(\"*.tif\"))\n",
    "mask_patches = list(mask_patches_dir.rglob(\"*.tif\"))\n",
    "print(len(img_patches), len(mask_patches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_L2A:\n",
    "    assert len(img_patches) // 2 == len(mask_patches)\n",
    "else:\n",
    "    assert len(img_patches) == len(mask_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7579201a4d5c43fc8e98efcbded1ec0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/87880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with Pool(4) as p:\n",
    "    results = list(tqdm(p.imap(check_imgs, img_patches), total=len(img_patches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eac20c2d0f84926a6315107c56d0c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43940 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with Pool(4) as p:\n",
    "    results = list(tqdm(p.imap(check_masks, mask_patches), total=len(mask_patches)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omniwatermask-training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
